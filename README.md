# تشخیص خطا در سامانه‌های صنعتی با شبکه عصبی گرافی مبتنی بر دانش پیشین

## معرفی

این پروژه پیاده‌سازی چارچوبی برای **تشخیص خطا و عیب‌یابی در سامانه‌های صنعتی چندسنسوره** با استفاده از **شبکه‌های عصبی گرافی (GNN)** و **ادغام صریح دانش پیشین ساختاری** است.

ایده اصلی پروژه بر ترکیب هم‌زمان دو منبع اطلاعاتی استوار است:

- **داده‌های حسگری:** سری‌های زمانی چندمتغیره پنجره‌بندی‌شده از سنسورهای فرایند
- **دانش پیشین ساختاری:** اطلاعات مربوط به روابط فیزیکی، علّی و کنترلی بین متغیرهای فرایند

مدل پیشنهادی قادر است ساختار گراف بین سنسورها را در چهار حالت مختلف مدیریت کند:

| حالت | توضیح |
|------|-------|
| **گراف ثابت** | ماتریس مجاورت فیزیکی بدون تغییر در طول آموزش |
| **گراف کاملاً قابل یادگیری** | یادگیری آزاد ساختار گراف از داده با مقداردهی تصادفی |
| **مقداردهی اولیه با دانش پیشین** | آغاز از گراف فیزیکی و ریزتنظیم داده‌محور |
| **ترکیبی (بخش ثابت و قابل یادگیری)** | ثابت نگه‌داشتن یال‌های مطمئن و یادگیری بقیه |

---

## معماری مدل

معماری شامل سه جزء اصلی است:

### ۱. بلوک تعیین ساختار گراف

تولید ماتریس مجاورت بر اساس سناریوی انتخاب‌شده. در حالات قابل یادگیری، یک ماتریس پارامتری `W` تعریف شده و ماتریس مجاورت از طریق `ReLU(W)` محاسبه می‌شود. امکان تنک‌سازی Top-k نیز وجود دارد.

### ۲. دو لایه پیچشی گرافی (GCN)

- نرمال‌سازی متقارن درجه
- تابع فعال‌سازی ReLU
- نرمال‌سازی دسته‌ای (BatchNorm1d)
- تجمیع کمینه (MinPool) روی بُعد گره‌ها
- اتصال میان‌بر (Skip Connection) از خروجی لایه اول به خروجی نهایی

### ۳. سر طبقه‌بندی‌کننده

یک لایه تمام‌متصل برای نگاشت بازنمایی سطح سیستم به فضای کلاس‌ها.

---

## ساختار پروژه

```
project_root/
│
├── scripts/
│   ├── train.py              # اسکریپت آموزش مدل
│   └── evaluate.py           # اسکریپت ارزیابی مدل
│
├── src/
│   └── models/
│       ├── baselines/
│       │   └── mlp.py        # مدل MLP (روش مبنا)
│       └── gnn/
│           ├── gsl.py                        # بلوک یادگیری گراف (پایه)
│           ├── gsl_with_prior.py             # بلوک گراف با مقداردهی اولیه
│           ├── gsl_with_partial_freeze.py    # بلوک گراف ترکیبی
│           ├── gnn_fixed_adj.py              # مدل GNN با گراف ثابت
│           ├── gnn_trainable_adj.py          # مدل GNN با گراف قابل یادگیری
│           ├── gnn_trainable_with_prior.py   # مدل GNN با مقداردهی پیشین
│           └── gnn_trainable_partial_freeze.py # مدل GNN ترکیبی
│
├── data/
│   └── adjacency/
│       └── TE_ground_truth.txt   # ماتریس مجاورت فیزیکی فرایند TEP
│
└── outputs/
    └── runs/                     # خروجی‌های آموزش
```

---

## پیش‌نیازها

### نصب وابستگی‌ها

```bash
pip install torch numpy pandas scikit-learn tqdm fddbenchmark
```

- Python 3.9 یا بالاتر
- PyTorch 2.0 یا بالاتر
- پکیج `fddbenchmark` برای بارگذاری دیتاست و ارزیابی

---

## مجموعه‌داده

این پروژه بر روی مجموعه‌داده **Reinartz TEP (Tennessee Eastman Process)** ارزیابی شده است. این مجموعه‌داده شامل ۵۳ متغیر فرایندی، ۲۸ سناریوی خطا و داده‌های عملکرد نرمال است. مجموعه‌داده به‌صورت خودکار توسط `fddbenchmark` بارگذاری می‌شود.

---

## آموزش مدل

تمام حالات مدل از طریق اسکریپت واحد `train.py` قابل اجرا هستند.

### حالت ۱: گراف ثابت مبتنی بر دانش فیزیکی

```bash
python scripts/train.py \
  --model_type gnn_fixed \
  --adj_path data/adjacency/TE_ground_truth.txt \
  --dataset reinartz_tep \
  --feature_mode te_33 \
  --window_size 100 \
  --n_hidden 1024 \
  --n_epochs 10 \
  --lr 1e-3 \
  --batch_size 512 \
  --seed 0
```

### حالت ۲: گراف کاملاً قابل یادگیری

```bash
python scripts/train.py \
  --model_type gnn_trainable \
  --dataset reinartz_tep \
  --feature_mode te_33 \
  --window_size 100 \
  --n_epochs 10 \
  --seed 0
```

### حالت ۳: مقداردهی اولیه با دانش پیشین

```bash
python scripts/train.py \
  --model_type gnn_trainable_prior \
  --prior_path data/adjacency/TE_ground_truth.txt \
  --dataset reinartz_tep \
  --feature_mode te_33 \
  --window_size 100 \
  --n_epochs 10 \
  --seed 0
```

### حالت ۴: گراف ترکیبی (بخش ثابت و قابل یادگیری)

```bash
python scripts/train.py \
  --model_type gnn_partial \
  --prior_path data/adjacency/TE_ground_truth.txt \
  --dataset reinartz_tep \
  --feature_mode te_33 \
  --window_size 100 \
  --n_epochs 10 \
  --seed 0
```

### مدل مبنا (MLP)

```bash
python scripts/train.py \
  --model_type mlp \
  --dataset reinartz_tep \
  --feature_mode te_33 \
  --window_size 100 \
  --n_epochs 10 \
  --seed 0
```

### آموزش با داده محدود

برای بررسی عملکرد مدل در شرایط کمبود داده، از پارامتر `--train_percent` استفاده کنید:

```bash
python scripts/train.py \
  --model_type gnn_trainable_prior \
  --prior_path data/adjacency/TE_ground_truth.txt \
  --train_percent 10 \
  --n_epochs 10 \
  --seed 0
```

---

## ارزیابی مدل

```bash
python scripts/evaluate.py \
  --model_path outputs/runs/<run_name>/model.pt \
  --model_type gnn_trainable_prior \
  --dataset reinartz_tep \
  --feature_mode te_33 \
  --window_size 100 \
  --batch_size 512
```

معیارهای ارزیابی توسط چارچوب `FDDBenchmark` به‌صورت خودکار محاسبه و گزارش می‌شوند و شامل نرخ تشخیص درست (TPR)، نرخ هشدار غلط (FPR)، میانگین تأخیر تشخیص (ADD) و نرخ عیب‌یابی صحیح (CDR) هستند.

---

## پارامترهای خط فرمان

### پارامترهای داده

| پارامتر | پیش‌فرض | توضیح |
|---------|---------|-------|
| `--dataset` | `reinartz_tep` | نام مجموعه‌داده |
| `--window_size` | `100` | طول پنجره زمانی |
| `--step_size` | `1` | گام لغزش پنجره |
| `--batch_size` | `512` | اندازه مینی‌بچ |
| `--feature_mode` | `te_33` | حالت انتخاب متغیرها (`te_33` یا `drop_29_41`) |
| `--train_percent` | `100.0` | درصد داده آموزشی (۱ تا ۱۰۰) |
| `--seed` | `0` | بذر تصادفی برای تکرارپذیری |

### پارامترهای مدل

| پارامتر | پیش‌فرض | توضیح |
|---------|---------|-------|
| `--model_type` | `mlp` | نوع مدل: `mlp`, `gnn_fixed`, `gnn_trainable`, `gnn_trainable_prior`, `gnn_partial` |
| `--n_hidden` | `1024` | بُعد فضای پنهان لایه‌های GCN |
| `--n_gnn` | `1` | تعداد ماژول‌های گرافی موازی |
| `--k` | `None` | پارامتر تنک‌سازی Top-k (غیرفعال اگر مشخص نشود) |

### پارامترهای ماتریس مجاورت

| پارامتر | توضیح |
|---------|-------|
| `--adj_path` | مسیر فایل ماتریس مجاورت برای حالت `gnn_fixed` |
| `--prior_path` | مسیر فایل ماتریس مجاورت فیزیکی برای حالت‌های `gnn_trainable_prior` و `gnn_partial` |

### پارامترهای آموزش

| پارامتر | پیش‌فرض | توضیح |
|---------|---------|-------|
| `--n_epochs` | `10` | تعداد دوره‌های آموزش |
| `--lr` | `1e-3` | نرخ یادگیری بهینه‌ساز Adam |
| `--save_dir` | `outputs/runs` | مسیر ذخیره خروجی‌ها |

---

## خروجی‌ها

برای هر اجرای آموزش، یک پوشه با نام منحصربه‌فرد ایجاد شده و فایل‌های زیر ذخیره می‌شوند:

| فایل | محتوا |
|------|-------|
| `model.pt` | مدل آموزش‌دیده شامل وزن‌ها و ساختار گراف |
| `config.json` | تمام ابرپارامترها و تنظیمات اجرا |
| `metrics.json` | تاریخچه تابع زیان آموزشی در هر دوره |

نام‌گذاری پوشه به فرمت زیر است:

```
{model_type}_tp{train_percent}_ws{window_size}_seed{seed}_ep{n_epochs}_{timestamp}
```

---

## مشخصات فنی مدل

| مشخصه | مقدار |
|-------|-------|
| تعداد گره‌ها (حالت te_33) | ۳۳ |
| بُعد ویژگی ورودی هر گره | ۱۰۰ (طول پنجره) |
| بُعد فضای پنهان | ۱۰۲۴ |
| تعداد لایه‌های GCN | ۲ |
| تجمیع سطح سیستم | MinPool |
| تعداد کلاس‌ها (TEP) | ۲۹ |
| تعداد تقریبی پارامترها | ۱.۱۸ میلیون |
| پارامترهای ساختار گراف | ۱,۰۸۹ (کمتر از ۰.۱٪ کل) |

---

## نکات مهم

- ابعاد ماتریس مجاورت باید دقیقاً با تعداد متغیرهای انتخاب‌شده مطابقت داشته باشد.
- نرمال‌سازی فقط بر اساس آمار داده‌های آموزشی انجام می‌شود تا از نشت اطلاعات جلوگیری شود.
- در حالت `gnn_partial`، یال‌هایی از ماتریس مجاورت فیزیکی که مقدار بزرگ‌تر از ۰.۵ دارند ثابت نگه‌داشته شده و بقیه قابل یادگیری هستند.
- فایل ماتریس مجاورت می‌تواند با فرمت `.npy` یا `.txt` ارائه شود.
- تمام آزمایش‌ها با بذر تصادفی ثابت قابل بازتولید هستند.
```